[CharLevelTokenizer] Training tokenizer from 3 files...
[CharLevelTokenizer] Processing "E:/Corpora & Language Resources/모두의 말뭉치/splits\modu-plm-dev.txt": 4230152it [01:46, 39790.96it/s]
[CharLevelTokenizer] Processing "E:/Corpora & Language Resources/모두의 말뭉치/splits\modu-plm-test.txt": 4230152it [01:46, 39861.67it/s]
[CharLevelTokenizer] Processing "E:/Corpora & Language Resources/모두의 말뭉치/splits\modu-plm-train.txt": 73177258it [25:23, 48030.99it/s]
(0) 테러방지법 반대 필리버스터 - 8일 경과.
25 [2, 16332, 13216, 13769, 15389, 13820, 5, 13752, 12715, 5, 16774, 13422, 13807, 14443, 16313, 5, 20, 5, 31, 15073, 5, 11944, 11983, 21, 3]
25 ['[CLS]', '테', '러', '방', '지', '법', '[S]', '반', '대', '[S]', '필', '리', '버', '스', '터', '[S]', '-', '[S]', '8', '일', '[S]', '경', '과', '.', '[SEP]']
[CLS]테러방지법[S]반대[S]필리버스터[S]-[S]8일[S]경과.[SEP]
input_ids: 50 [2, 16332, 13216, 13769, 15389, 13820, 5, 13752, 12715, 5, 16774, 13422, 13807, 14443, 16313, 5, 20, 5, 31, 15073, 5, 11944, 11983, 21, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
masked_input_ids: 50 [2, 16332, 13216, 13769, 15389, 13820, 5, 13752, 12715, 5, 16774, 13422, 13807, 5637, 16313, 5, 4, 4, 31, 15073, 5, 11944, 11983, 21, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
token_type_ids: 50 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
attention_mask: 50 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
['[CLS]', '테', '러', '방', '지', '법', '[S]', '반', '대', '[S]', '필', '리', '버', '朓', '터', '[S]', '[MASK]', '[MASK]', '8', '일', '[S]', '경', '과', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']


Model: "BOAT"
______________________________________________________________________________________________________________________________________________________
Layer (type)                                     Output Shape                     Param #           Connected to
======================================================================================================================================================
CharLevelInputLayer (InputLayer)                 [(None, 2, 512)]                 0
______________________________________________________________________________________________________________________________________________________
FactorizedEmbeddingLayer (FactorizedEmbeddingLay ((None, 512, 128), (None, 1, 1,  1291584           CharLevelInputLayer[0][0]
______________________________________________________________________________________________________________________________________________________
TransformerStackedEncoderLayers (TransformerStac ((None, 512, 128), (None, 1, 1,  99584             FactorizedEmbeddingLayer[0][0]
                                                                                                    FactorizedEmbeddingLayer[0][1]
______________________________________________________________________________________________________________________________________________________
TransformerPostEncoderDenseLayer (TransformerPos (None, 512, 19023)               2470479           TransformerStackedEncoderLayers[0][0]
                                                                                                    TransformerStackedEncoderLayers[0][1]
======================================================================================================================================================
Total params: 3,861,647
Trainable params: 3,861,647
Non-trainable params: 0
______________________________________________________________________________________________________________________________________________________
DYNAMIC_STRIP : True
MAX_LENGTH : 512
VOCAB_SIZE : 19023
EMBEDDING_DIM : 128
FACTORIZED_DIM : 64
CROSS_LAYER_SHARING : True
NUM_HEADS : 4
FEEDFORWARD_DIM : 128
NUM_LAYERS : 4
DROPOUT_RATE : 0.1
BATCH_SIZE : 16
LEARNING_RATE : 0.0001
EPOCHS : 1000
SAVED_MODEL_PATH : saved_model
